{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e86332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to predict the ucl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3a66a",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 151\u001b[39m\n\u001b[32m    146\u001b[39m             df.loc[team_matches.index, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_Points_rolling\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = team_matches[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_Points_rolling\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m]\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m train_data = pd.concat([\u001b[43mbuild_match_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m train_seasons], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    152\u001b[39m test_data = pd.concat([build_match_dataset(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m test_seasons], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# Add rolling form\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mbuild_match_dataset\u001b[39m\u001b[34m(season)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_match_dataset\u001b[39m(season):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     fixtures = \u001b[43mload_fixtures_for_season\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseason\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# load fixtures for given season\u001b[39;00m\n\u001b[32m     95\u001b[39m     stats = load_stats_for_season(season) \u001b[38;5;66;03m# load stats for a given season\u001b[39;00m\n\u001b[32m     97\u001b[39m     merged = fixtures.merge(stats, left_on=\u001b[33m\"\u001b[39m\u001b[33mHomeTeam\u001b[39m\u001b[33m\"\u001b[39m, right_on=\u001b[33m\"\u001b[39m\u001b[33mSquad\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m, suffixes=(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_Home\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mload_fixtures_for_season\u001b[39m\u001b[34m(season)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_fixtures_for_season\u001b[39m(season): \u001b[38;5;66;03m# scrapes one season's fixtures/results from FBRef\u001b[39;00m\n\u001b[32m     45\u001b[39m     url = fixture_urls[season] \u001b[38;5;66;03m# get the page url for this season\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     tables = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhtml5lib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     df = tables[\u001b[32m0\u001b[39m].copy() \u001b[38;5;66;03m# the first table is the full fixture table\u001b[39;00m\n\u001b[32m     48\u001b[39m     df = df.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mHome\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHomeTeam\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAway\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mAwayTeam\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:983\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    972\u001b[39m p = parser(\n\u001b[32m    973\u001b[39m     io,\n\u001b[32m    974\u001b[39m     compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m     storage_options,\n\u001b[32m    980\u001b[39m )\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     tables = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[32m    986\u001b[39m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[33m\"\u001b[39m\u001b[33mseekable\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io.seekable():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:249\u001b[39m, in \u001b[36m_HtmlFrameParser.parse_tables\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[32m    244\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m \u001b[33;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     tables = \u001b[38;5;28mself\u001b[39m._parse_tables(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.match, \u001b[38;5;28mself\u001b[39m.attrs)\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:653\u001b[39m, in \u001b[36m_BeautifulSoupHtml5LibFrameParser._build_doc\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_build_doc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     bdoc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bdoc, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    655\u001b[39m         udoc = bdoc.decode(\u001b[38;5;28mself\u001b[39m.encoding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:645\u001b[39m, in \u001b[36m_BeautifulSoupHtml5LibFrameParser._setup_build_doc\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_setup_build_doc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m645\u001b[39m     raw_text = \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_text:\n\u001b[32m    647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo text parsed from document: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.io\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:143\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(obj, encoding, storage_options)\u001b[39m\n\u001b[32m    137\u001b[39m text: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    139\u001b[39m     is_url(obj)\n\u001b[32m    140\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    141\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m file_exists(obj))\n\u001b[32m    142\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    146\u001b[39m         text = handles.handle.read()\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# loading the datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings # to supress harmless warninigs\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Fbref scores and fixtures urls per season\n",
    "fixture_urls = {\"2025-26\" : \"https://fbref.com/en/comps/9/schedule/Premier-League-Scores-and-Fixtures\",\n",
    "                \"2024-25\" :\"https://fbref.com/en/comps/9/2024-2025/schedule/2024-2025-Premier-League-Scores-and-Fixtures\",\n",
    "                \"2023-24\" :\"https://fbref.com/en/comps/9/2023-2024/schedule/2023-2024-Premier-League-Scores-and-Fixtures\",\n",
    "                \"2022-23\" :\"https://fbref.com/en/comps/9/2022-2023/schedule/2022-2023-Premier-League-Scores-and-Fixtures\",\n",
    "                \"2021-22\" : \"https://fbref.com/en/comps/9/2021-2022/schedule/2021-2022-Premier-League-Scores-and-Fixtures\",\n",
    "                \"2020-21\" : \"https://fbref.com/en/comps/9/2020-2021/schedule/2020-2021-Premier-League-Scores-and-Fixtures\"\n",
    "               }\n",
    "                \n",
    "\n",
    "stats_urls = {\"2025-26\" : \"https://fbref.com/en/comps/9/stats/Premier-League-Stats\",\n",
    "              \"2024-25\" : \"https://fbref.com/en/comps/9/2024-2025/stats/2024-2025-Premier-League-Stats\",  # latest full stats season\n",
    "              \"2023-24\": \"https://fbref.com/en/comps/9/2023-2024/stats/2023-2024-Premier-League-Stats\",  # previous\n",
    "              \"2022-23\": \"https://fbref.com/en/comps/9/2022-2023/stats/2022-2023-Premier-League-Stats\",\n",
    "              \"2021-22\" : \"https://fbref.com/en/comps/9/2021-2022/stats/2021-2022-Premier-League-Stats\",\n",
    "              \"2020-21\" : \"https://fbref.com/en/comps/9/2020-2021/stats/2020-2021-Premier-League-Stats\"}  # previous\n",
    "\n",
    "train_seasons = [\"2020-21\",\"2021-22\",\"2022-23\", \"2023-24\"]\n",
    "test_seasons = [\"2024-25\"]\n",
    "predict_season = [\"2025-26\"]\n",
    "\n",
    "stats_cols = [\"Squad\", \"Goals\", \"Ast\", \"G+A\", \"Gls/90\", \"Ast/90\", \"G+A/90\", \"xG\", \"xGA\", \"Poss\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## parsing and loading\n",
    "\n",
    "def split_score_to_goals(score_series):\n",
    "    extracted = score_series.astype(str).str.extract(\n",
    "        r'(?P<HomeGoals>\\d+)\\s*[-–:]\\s*(?P<AwayGoals>\\d+)'\n",
    "    )\n",
    "    return extracted.astype(float).astype(\"Int64\") \n",
    "\n",
    "\n",
    "def load_fixtures_for_season(season): # scrapes one season's fixtures/results from FBRef\n",
    "    url = fixture_urls[season] # get the page url for this season\n",
    "    tables = pd.read_html(url,flavor=\"html5lib\")\n",
    "    df = tables[0].copy() # the first table is the full fixture table\n",
    "    df = df.rename(columns={\"Home\": \"HomeTeam\", \"Away\": \"AwayTeam\"})\n",
    "    df[\"Season\"] = season\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    goals = split_score_to_goals(df[\"Score\"]) # plit score into numeric home and away goals\n",
    "    df = pd.concat([df, goals], axis=1) # attach goals coloums\n",
    "\n",
    "    df[\"is_played\"] = df[\"HomeGoals\"].notna() & df[\"AwayGoals\"].notna() # mark completed matches\n",
    "\n",
    "    df[\"Result\"] = pd.NA\n",
    "\n",
    "    # Fill only for played games\n",
    "    mask = df[\"is_played\"]\n",
    "    df.loc[mask & (df[\"HomeGoals\"] > df[\"AwayGoals\"]), \"Result\"] = \"HomeWin\"\n",
    "    df.loc[mask & (df[\"AwayGoals\"] > df[\"HomeGoals\"]), \"Result\"] = \"AwayWin\"\n",
    "    df.loc[mask & (df[\"HomeGoals\"] == df[\"AwayGoals\"]), \"Result\"] = \"Draw\"\n",
    "\n",
    "    keep = [\"Season\", \"Date\", \"HomeTeam\", \"AwayTeam\", \"Score\", \n",
    "            \"HomeGoals\", \"AwayGoals\", \"Result\", \"is_played\"]\n",
    "    return df[keep].reset_index(drop=True)\n",
    "    \n",
    "#print(load_fixtures_for_season(\"2023-24\").head(10))\n",
    "\n",
    "def load_stats_for_season(season): # load the team standard stats\n",
    "    url = stats_urls[season] # get the stats url page for this season\n",
    "    headers = {\"User Agent\"}\n",
    "    tables = pd.read_html(url, flavor=\"html5lib\")\n",
    "    base = tables[0].copy()\n",
    "\n",
    "    # Flatten headers → take last row of header tuple\n",
    "    base.columns = [col[-1] if isinstance(col, tuple) else col for col in base.columns]\n",
    "\n",
    "    # Drop unnamed junk columns\n",
    "    base = base.loc[:, ~base.columns.str.contains(\"Unnamed\")]\n",
    "\n",
    "    # Keep relevant stats\n",
    "    keep_cols = [\n",
    "        \"Squad\", \"Poss\", \"Gls\", \"Ast\", \"G+A\", \"Gls/90\", \"Ast/90\", \"G+A/90\",\n",
    "        \"xG\", \"npxG\", \"xAG\", \"npxG+xAG\", \"PrgC\", \"PrgP\"\n",
    "    ]\n",
    "    base = base[[c for c in keep_cols if c in base.columns]]\n",
    "\n",
    "    return base.reset_index(drop=True)\n",
    "\n",
    "#print(load_stats_for_season(\"2024-25\").head(20))\n",
    "\n",
    "def build_match_dataset(season):\n",
    "    fixtures = load_fixtures_for_season(season) # load fixtures for given season\n",
    "    stats = load_stats_for_season(season) # load stats for a given season\n",
    "\n",
    "    merged = fixtures.merge(stats, left_on=\"HomeTeam\", right_on=\"Squad\", how=\"left\", suffixes=(\"\", \"_Home\"))\n",
    "    merged = merged.drop(columns=[\"Squad\"]) # drop the duplicate Squad coloum\n",
    "    merged = merged.rename(columns={c: f\"Home_{c}\" for c in merged.columns if c not in fixtures.columns}) # prefix the home stats with \"Home_\"\n",
    "\n",
    "    merged = merged.merge(stats, left_on=\"AwayTeam\", right_on=\"Squad\", how=\"left\", suffixes=(\"\", \"_Away\"))\n",
    "    merged = merged.drop(columns=[\"Squad\"]) # drop the duplicate Squad coloum\n",
    "    merged = merged.rename(columns={c: f\"Away_{c}\" for c in merged.columns if c not in fixtures.columns}) # prefix the away stats with \"Away_\"\n",
    "    \n",
    "    return merged\n",
    "\n",
    "#print(build_match_dataset(\"2023-24\").head(10))\n",
    "\n",
    "def add_rolling_form_features(df, window=5):\n",
    "    \"\"\"\n",
    "    Adds rolling form features for both Home and Away teams.\n",
    "    Uses last `window` matches before each fixture.\n",
    "    \"\"\"\n",
    "    form_features = [\"HomeGoals\", \"AwayGoals\"]  # you can add more like xG if available\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    new_features = []\n",
    "\n",
    "    for team_col, prefix in [(\"HomeTeam\", \"HomeForm\"), (\"AwayTeam\", \"AwayForm\")]:\n",
    "        for f in [\"Goals_For\", \"Goals_Against\", \"Points\"]:\n",
    "            new_features.append(f\"{prefix}_{f}_rolling{window}\")\n",
    "\n",
    "        # Expand fixtures per team\n",
    "        for team in df[team_col].unique():\n",
    "            team_matches = df[(df[\"HomeTeam\"] == team) | (df[\"AwayTeam\"] == team)].copy()\n",
    "            team_matches = team_matches.sort_values(\"Date\")\n",
    "\n",
    "            # Calculate goals for/against\n",
    "            team_matches[\"Goals_For\"] = np.where(team_matches[\"HomeTeam\"] == team,\n",
    "                                                 team_matches[\"HomeGoals\"], team_matches[\"AwayGoals\"])\n",
    "            team_matches[\"Goals_Against\"] = np.where(team_matches[\"HomeTeam\"] == team,\n",
    "                                                     team_matches[\"AwayGoals\"], team_matches[\"HomeGoals\"])\n",
    "\n",
    "            # Calculate points\n",
    "            team_matches[\"Points\"] = np.where(team_matches[\"Goals_For\"] > team_matches[\"Goals_Against\"], 3,\n",
    "                                     np.where(team_matches[\"Goals_For\"] == team_matches[\"Goals_Against\"], 1, 0))\n",
    "\n",
    "            # Rolling averages\n",
    "            team_matches[f\"{prefix}_Goals_For_rolling{window}\"] = team_matches[\"Goals_For\"].rolling(window).mean().shift(1)\n",
    "            team_matches[f\"{prefix}_Goals_Against_rolling{window}\"] = team_matches[\"Goals_Against\"].rolling(window).mean().shift(1)\n",
    "            team_matches[f\"{prefix}_Points_rolling{window}\"] = team_matches[\"Points\"].rolling(window).mean().shift(1)\n",
    "\n",
    "            # Merge back\n",
    "            df.loc[team_matches.index, f\"{prefix}_Goals_For_rolling{window}\"] = team_matches[f\"{prefix}_Goals_For_rolling{window}\"]\n",
    "            df.loc[team_matches.index, f\"{prefix}_Goals_Against_rolling{window}\"] = team_matches[f\"{prefix}_Goals_Against_rolling{window}\"]\n",
    "            df.loc[team_matches.index, f\"{prefix}_Points_rolling{window}\"] = team_matches[f\"{prefix}_Points_rolling{window}\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_data = pd.concat([build_match_dataset(s) for s in train_seasons], ignore_index=True)\n",
    "test_data = pd.concat([build_match_dataset(s) for s in test_seasons], ignore_index=True)\n",
    "\n",
    "# Add rolling form\n",
    "train_data = add_rolling_form_features(train_data, window=5)\n",
    "test_data = add_rolling_form_features(test_data, window=5)\n",
    "\n",
    "# Keep played matches only\n",
    "train_data = train_data[train_data[\"is_played\"]]\n",
    "test_data = test_data[test_data[\"is_played\"]]\n",
    "\n",
    "# Select features (include rolling form features now)\n",
    "feature_cols = [c for c in train_data.columns if (\"Home_\" in c or \"Away_\" in c) and c not in [\"HomeTeam\", \"AwayTeam\"]]\n",
    "\n",
    "X_train = train_data[feature_cols] #training features\n",
    "y_train = train_data[\"Result\"]\n",
    "\n",
    "X_test = test_data[feature_cols] # testing features\n",
    "y_test = test_data[\"Result\"]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42) # define random forest with 200 forest\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))  # Print confusion matrix (true vs predicted results)\n",
    "\n",
    "\n",
    "# === Step 6: Prepare prediction dataset for 2025-26 season ===\n",
    "predict_data = build_match_dataset(\"2025-26\")  # Build dataset with 2025-26 fixtures and stats\n",
    "\n",
    "# Keep only unplayed matches from the future season for prediction\n",
    "future_matches = predict_data[~predict_data[\"is_played\"]]  \n",
    "\n",
    "X_future = future_matches[feature_cols]  # Features for future matches\n",
    "future_matches[\"Predicted_Result\"] = rf.predict(X_future)  # Predict results for unplayed games\n",
    "\n",
    "# Print first 15 predicted results for upcoming matches\n",
    "print(\"\\nUpcoming Predictions (2025-26):\")\n",
    "print(future_matches[[\"Date\", \"HomeTeam\", \"AwayTeam\", \"Predicted_Result\"]].head(25))  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d963cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# === Build datasets ===\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m train_data = pd.concat([\u001b[43mbuild_match_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m train_seasons], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     91\u001b[39m test_data = pd.concat([build_match_dataset(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m test_seasons], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     93\u001b[39m train_data = add_rolling_form_features(train_data, window=\u001b[32m5\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mbuild_match_dataset\u001b[39m\u001b[34m(season)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_match_dataset\u001b[39m(season):\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     fixtures = \u001b[43mload_fixtures_for_season\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseason\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     stats = load_stats_for_season(season)\n\u001b[32m     67\u001b[39m     merged = fixtures.merge(stats, left_on=\u001b[33m\"\u001b[39m\u001b[33mHomeTeam\u001b[39m\u001b[33m\"\u001b[39m, right_on=\u001b[33m\"\u001b[39m\u001b[33mSquad\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mload_fixtures_for_season\u001b[39m\u001b[34m(season)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_fixtures_for_season\u001b[39m(season):\n\u001b[32m     37\u001b[39m     url = fixture_urls[season]\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     tables = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhtml5lib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     df = tables[\u001b[32m0\u001b[39m].copy()\n\u001b[32m     40\u001b[39m     df = df.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mHome\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHomeTeam\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAway\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mAwayTeam\u001b[39m\u001b[33m\"\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:1240\u001b[39m, in \u001b[36mread_html\u001b[39m\u001b[34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m   1225\u001b[39m     [\n\u001b[32m   1226\u001b[39m         is_file_like(io),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1230\u001b[39m     ]\n\u001b[32m   1231\u001b[39m ):\n\u001b[32m   1232\u001b[39m     warnings.warn(\n\u001b[32m   1233\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing literal html to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mread_html\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1234\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in a future version. To read from a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:983\u001b[39m, in \u001b[36m_parse\u001b[39m\u001b[34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[39m\n\u001b[32m    972\u001b[39m p = parser(\n\u001b[32m    973\u001b[39m     io,\n\u001b[32m    974\u001b[39m     compiled_match,\n\u001b[32m   (...)\u001b[39m\u001b[32m    979\u001b[39m     storage_options,\n\u001b[32m    980\u001b[39m )\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     tables = \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[32m    986\u001b[39m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[33m\"\u001b[39m\u001b[33mseekable\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io.seekable():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:249\u001b[39m, in \u001b[36m_HtmlFrameParser.parse_tables\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[32m    244\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m \u001b[33;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     tables = \u001b[38;5;28mself\u001b[39m._parse_tables(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.match, \u001b[38;5;28mself\u001b[39m.attrs)\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:653\u001b[39m, in \u001b[36m_BeautifulSoupHtml5LibFrameParser._build_doc\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_build_doc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    651\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     bdoc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bdoc, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    655\u001b[39m         udoc = bdoc.decode(\u001b[38;5;28mself\u001b[39m.encoding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:645\u001b[39m, in \u001b[36m_BeautifulSoupHtml5LibFrameParser._setup_build_doc\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    644\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_setup_build_doc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m645\u001b[39m     raw_text = \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_text:\n\u001b[32m    647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo text parsed from document: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.io\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/html.py:143\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(obj, encoding, storage_options)\u001b[39m\n\u001b[32m    137\u001b[39m text: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    139\u001b[39m     is_url(obj)\n\u001b[32m    140\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    141\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m file_exists(obj))\n\u001b[32m    142\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    146\u001b[39m         text = handles.handle.read()\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:521\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    520\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:630\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:559\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    558\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/urllib/request.py:639\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 429: Too Many Requests"
     ]
    }
   ],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === FBRef URLs ===\n",
    "fixture_urls = {\n",
    "    \"2025-26\": \"https://fbref.com/en/comps/9/schedule/Premier-League-Scores-and-Fixtures\",\n",
    "    \"2024-25\": \"https://fbref.com/en/comps/9/2024-2025/schedule/2024-2025-Premier-League-Scores-and-Fixtures\",\n",
    "    \"2023-24\": \"https://fbref.com/en/comps/9/2023-2024/schedule/2023-2024-Premier-League-Scores-and-Fixtures\",\n",
    "    \"2022-23\": \"https://fbref.com/en/comps/9/2022-2023/schedule/2022-2023-Premier-League-Scores-and-Fixtures\",\n",
    "    \"2021-22\": \"https://fbref.com/en/comps/9/2021-2022/schedule/2021-2022-Premier-League-Scores-and-Fixtures\",\n",
    "    \"2020-21\": \"https://fbref.com/en/comps/9/2020-2021/schedule/2020-2021-Premier-League-Scores-and-Fixtures\"\n",
    "}\n",
    "\n",
    "stats_urls = {\n",
    "    \"2025-26\": \"https://fbref.com/en/comps/9/stats/Premier-League-Stats\",\n",
    "    \"2024-25\": \"https://fbref.com/en/comps/9/2024-2025/stats/2024-2025-Premier-League-Stats\",\n",
    "    \"2023-24\": \"https://fbref.com/en/comps/9/2023-2024/stats/2023-2024-Premier-League-Stats\",\n",
    "    \"2022-23\": \"https://fbref.com/en/comps/9/2022-2023/stats/2022-2023-Premier-League-Stats\",\n",
    "    \"2021-22\": \"https://fbref.com/en/comps/9/2021-2022/stats/2021-2022-Premier-League-Stats\",\n",
    "    \"2020-21\": \"https://fbref.com/en/comps/9/2020-2021/stats/2020-2021-Premier-League-Stats\"\n",
    "}\n",
    "\n",
    "train_seasons = [\"2020-21\",\"2021-22\",\"2022-23\",\"2023-24\"]\n",
    "test_seasons = [\"2024-25\"]\n",
    "\n",
    "# === Helper Functions ===\n",
    "def split_score_to_goals(score_series):\n",
    "    extracted = score_series.astype(str).str.extract(r'(?P<HomeGoals>\\d+)\\s*[-–:]\\s*(?P<AwayGoals>\\d+)')\n",
    "    return extracted.astype(float).astype(\"Int64\")\n",
    "\n",
    "def load_fixtures_for_season(season):\n",
    "    url = fixture_urls[season]\n",
    "    tables = pd.read_html(url, flavor=\"html5lib\")\n",
    "    df = tables[0].copy()\n",
    "    df = df.rename(columns={\"Home\": \"HomeTeam\", \"Away\": \"AwayTeam\"})\n",
    "    df[\"Season\"] = season\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "    goals = split_score_to_goals(df[\"Score\"])\n",
    "    df = pd.concat([df, goals], axis=1)\n",
    "    df[\"is_played\"] = df[\"HomeGoals\"].notna() & df[\"AwayGoals\"].notna()\n",
    "    df[\"Result\"] = pd.NA\n",
    "    mask = df[\"is_played\"]\n",
    "    df.loc[mask & (df[\"HomeGoals\"] > df[\"AwayGoals\"]), \"Result\"] = \"HomeWin\"\n",
    "    df.loc[mask & (df[\"AwayGoals\"] > df[\"HomeGoals\"]), \"Result\"] = \"AwayWin\"\n",
    "    df.loc[mask & (df[\"HomeGoals\"] == df[\"AwayGoals\"]), \"Result\"] = \"Draw\"\n",
    "    keep = [\"Season\", \"Date\", \"HomeTeam\", \"AwayTeam\", \"Score\", \"HomeGoals\", \"AwayGoals\", \"Result\", \"is_played\"]\n",
    "    return df[keep].reset_index(drop=True)\n",
    "\n",
    "def load_stats_for_season(season):\n",
    "    url = stats_urls[season]\n",
    "    tables = pd.read_html(url, flavor=\"html5lib\")\n",
    "    base = tables[0].copy()\n",
    "    base.columns = [col[-1] if isinstance(col, tuple) else col for col in base.columns]\n",
    "    base = base.loc[:, ~base.columns.str.contains(\"Unnamed\")]\n",
    "    keep_cols = [\"Squad\", \"Poss\", \"Gls\", \"Ast\", \"G+A\", \"Gls/90\", \"Ast/90\", \"G+A/90\", \"xG\", \"npxG\", \"xAG\", \"npxG+xAG\", \"PrgC\", \"PrgP\"]\n",
    "    base = base[[c for c in keep_cols if c in base.columns]]\n",
    "    return base.reset_index(drop=True)\n",
    "\n",
    "def build_match_dataset(season):\n",
    "    fixtures = load_fixtures_for_season(season)\n",
    "    stats = load_stats_for_season(season)\n",
    "    merged = fixtures.merge(stats, left_on=\"HomeTeam\", right_on=\"Squad\", how=\"left\")\n",
    "    merged = merged.drop(columns=[\"Squad\"])\n",
    "    merged = merged.rename(columns={c: f\"Home_{c}\" for c in merged.columns if c not in fixtures.columns})\n",
    "    merged = merged.merge(stats, left_on=\"AwayTeam\", right_on=\"Squad\", how=\"left\")\n",
    "    merged = merged.drop(columns=[\"Squad\"])\n",
    "    merged = merged.rename(columns={c: f\"Away_{c}\" for c in merged.columns if c not in fixtures.columns})\n",
    "    return merged\n",
    "\n",
    "def add_rolling_form_features(df, window=5):\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "    for team_col, prefix in [(\"HomeTeam\", \"HomeForm\"), (\"AwayTeam\", \"AwayForm\")]:\n",
    "        for team in df[team_col].unique():\n",
    "            team_matches = df[(df[\"HomeTeam\"]==team) | (df[\"AwayTeam\"]==team)].sort_values(\"Date\").copy()\n",
    "            team_matches[\"Goals_For\"] = np.where(team_matches[\"HomeTeam\"]==team, team_matches[\"HomeGoals\"], team_matches[\"AwayGoals\"])\n",
    "            team_matches[\"Goals_Against\"] = np.where(team_matches[\"HomeTeam\"]==team, team_matches[\"AwayGoals\"], team_matches[\"HomeGoals\"])\n",
    "            team_matches[\"Points\"] = np.where(team_matches[\"Goals_For\"]>team_matches[\"Goals_Against\"],3,\n",
    "                                      np.where(team_matches[\"Goals_For\"]==team_matches[\"Goals_Against\"],1,0))\n",
    "            for stat in [\"Goals_For\",\"Goals_Against\",\"Points\"]:\n",
    "                team_matches[f\"{prefix}_{stat}_rolling{window}\"] = team_matches[stat].rolling(window).mean().shift(1)\n",
    "                df.loc[team_matches.index, f\"{prefix}_{stat}_rolling{window}\"] = team_matches[f\"{prefix}_{stat}_rolling{window}\"]\n",
    "    return df\n",
    "\n",
    "# === Build datasets ===\n",
    "train_data = pd.concat([build_match_dataset(s) for s in train_seasons], ignore_index=True)\n",
    "test_data = pd.concat([build_match_dataset(s) for s in test_seasons], ignore_index=True)\n",
    "\n",
    "train_data = add_rolling_form_features(train_data, window=5)\n",
    "test_data = add_rolling_form_features(test_data, window=5)\n",
    "\n",
    "train_data = train_data[train_data[\"is_played\"]].fillna(0)\n",
    "test_data = test_data[test_data[\"is_played\"]].fillna(0)\n",
    "\n",
    "# === Features & Labels ===\n",
    "feature_cols = [c for c in train_data.columns if (\"Home_\" in c or \"Away_\" in c) and c not in [\"HomeTeam\",\"AwayTeam\"]]\n",
    "# ensure numeric only\n",
    "feature_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(train_data[c])]\n",
    "\n",
    "X_train = train_data[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "X_test = test_data[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "y_map = {\"AwayWin\":2, \"Draw\":1.5, \"HomeWin\":1}\n",
    "y_train_enc = train_data[\"Result\"].map(y_map)\n",
    "y_test_enc = test_data[\"Result\"].map(y_map)\n",
    "\n",
    "# === Train XGBoost ===\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=3,\n",
    "    random_state=42,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    use_label_encoder=False\n",
    ")\n",
    "model.fit(X_train, y_train_enc)\n",
    "\n",
    "# === Evaluation ===\n",
    "y_pred_enc = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_enc, y_pred_enc))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_enc, y_pred_enc, target_names=list(y_map.keys())))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_enc, y_pred_enc))\n",
    "\n",
    "# === Predict 2025-26 ===\n",
    "predict_data = build_match_dataset(\"2025-26\")\n",
    "predict_data = add_rolling_form_features(predict_data, window=5)\n",
    "future_matches = predict_data[~predict_data[\"is_played\"]].fillna(0)\n",
    "X_future = future_matches[feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "future_matches[\"Predicted_Result\"] = model.predict(X_future)\n",
    "future_matches[\"Predicted_Result\"] = future_matches[\"Predicted_Result\"].map({v:k for k,v in y_map.items()})\n",
    "\n",
    "print(\"\\nUpcoming Predictions (2025-26):\")\n",
    "print(future_matches[[\"Date\",\"HomeTeam\",\"AwayTeam\",\"Predicted_Result\"]].head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2274c86",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://fbref.com/en/comps/9/2021-2022/schedule/2021-2022-Premier-League-Scores-and-Fixtures",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 136\u001b[39m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m# === Step 3: Build datasets ===\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m train_data = pd.concat([\u001b[43mbuild_match_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m train_seasons], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    137\u001b[39m test_data = pd.concat([build_match_dataset(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m test_seasons], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    139\u001b[39m train_data = add_rolling_form_features(train_data, window=\u001b[32m5\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 96\u001b[39m, in \u001b[36mbuild_match_dataset\u001b[39m\u001b[34m(season)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_match_dataset\u001b[39m(season):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     fixtures = \u001b[43mload_fixtures_for_season\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseason\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m     stats = load_stats_for_season(season)\n\u001b[32m     99\u001b[39m     merged = fixtures.merge(stats, left_on=\u001b[33m\"\u001b[39m\u001b[33mHomeTeam\u001b[39m\u001b[33m\"\u001b[39m, right_on=\u001b[33m\"\u001b[39m\u001b[33mSquad\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m, suffixes=(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_Home\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mload_fixtures_for_season\u001b[39m\u001b[34m(season)\u001b[39m\n\u001b[32m     51\u001b[39m url = fixture_urls[season]\n\u001b[32m     52\u001b[39m response = requests.get(url, headers=headers)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m soup = BeautifulSoup(response.text, \u001b[33m\"\u001b[39m\u001b[33mlxml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m tables = pd.read_html(\u001b[38;5;28mstr\u001b[39m(soup))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/9/2021-2022/schedule/2021-2022-Premier-League-Scores-and-Fixtures"
     ]
    }
   ],
   "source": [
    "# === Step 0: Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# === Step 1: Constants ===\n",
    "fixture_urls = {\n",
    "    \"2025-26\": \"https://fbref.com/en/comps/9/schedule/Premier-League-Scores-and-Fixtures\",\n",
    "    \"2024-25\": \"https://fbref.com/en/comps/9/2024-2025/schedule/2024-2025-Premier-League-Scores-and-Fixtures\",\n",
    "    \"2023-24\": \"https://fbref.com/en/comps/9/2023-2024/schedule/2023-2024-Premier-League-Scores-and-Fixtures\",\n",
    "    \"2022-23\": \"https://fbref.com/en/comps/9/2022-2023/schedule/2022-2023-Premier-League-Scores-and-Fixtures\",\n",
    "    \"2021-22\": \"https://fbref.com/en/comps/9/2021-2022/schedule/2021-2022-Premier-League-Scores-and-Fixtures\",\n",
    "    \"2020-21\": \"https://fbref.com/en/comps/9/2020-2021/schedule/2020-2021-Premier-League-Scores-and-Fixtures\"\n",
    "}\n",
    "\n",
    "stats_urls = {\n",
    "    \"2025-26\": \"https://fbref.com/en/comps/9/stats/Premier-League-Stats\",\n",
    "    \"2024-25\": \"https://fbref.com/en/comps/9/2024-2025/stats/2024-2025-Premier-League-Stats\",\n",
    "    \"2023-24\": \"https://fbref.com/en/comps/9/2023-2024/stats/2023-2024-Premier-League-Stats\",\n",
    "    \"2022-23\": \"https://fbref.com/en/comps/9/2022-2023/stats/2022-2023-Premier-League-Stats\",\n",
    "    \"2021-22\": \"https://fbref.com/en/comps/9/2021-2022/stats/2021-2022-Premier-League-Stats\",\n",
    "   \"2020-21\": \"https://fbref.com/en/comps/9/2020-2021/stats/2020-2021-Premier-League-Stats\"\n",
    "}\n",
    "\n",
    "train_seasons = [ \"2021-22\", \"2022-23\", \"2023-24\"]\n",
    "test_seasons = [\"2024-25\"]\n",
    "predict_season = [\"2025-26\"]\n",
    "\n",
    "# === Step 2: Utility Functions ===\n",
    "\n",
    "def split_score_to_goals(score_series):\n",
    "    extracted = score_series.astype(str).str.extract(\n",
    "        r'(?P<HomeGoals>\\d+)\\s*[-–:]\\s*(?P<AwayGoals>\\d+)'\n",
    "    )\n",
    "    return extracted.astype(float).astype(\"Int64\")\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
    "    \"Referer\": \"https://www.google.com/\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "}\n",
    "\n",
    "def load_fixtures_for_season(season):\n",
    "    url = fixture_urls[season]\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    tables = pd.read_html(str(soup))\n",
    "    \n",
    "    df = tables[0].copy()\n",
    "    df = df.rename(columns={\"Home\": \"HomeTeam\", \"Away\": \"AwayTeam\"})\n",
    "    df[\"Season\"] = season\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "    goals = split_score_to_goals(df[\"Score\"])\n",
    "    df = pd.concat([df, goals], axis=1)\n",
    "\n",
    "    df[\"is_played\"] = df[\"HomeGoals\"].notna() & df[\"AwayGoals\"].notna()\n",
    "    df[\"Result\"] = pd.NA\n",
    "\n",
    "    mask = df[\"is_played\"]\n",
    "    df.loc[mask & (df[\"HomeGoals\"] > df[\"AwayGoals\"]), \"Result\"] = \"HomeWin\"\n",
    "    df.loc[mask & (df[\"AwayGoals\"] > df[\"HomeGoals\"]), \"Result\"] = \"AwayWin\"\n",
    "    df.loc[mask & (df[\"HomeGoals\"] == df[\"AwayGoals\"]), \"Result\"] = \"Draw\"\n",
    "\n",
    "    keep = [\"Season\", \"Date\", \"HomeTeam\", \"AwayTeam\", \"Score\",\n",
    "            \"HomeGoals\", \"AwayGoals\", \"Result\", \"is_played\"]\n",
    "    return df[keep].reset_index(drop=True)\n",
    "\n",
    "def load_stats_for_season(season):\n",
    "    url = stats_urls[season]\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text,\"lxml\")\n",
    "    tables = pd.read_html(str(soup))\n",
    "\n",
    "    base = tables[0].copy()\n",
    "    base.columns = [col[-1] if isinstance(col, tuple) else col for col in base.columns]\n",
    "    base = base.loc[:, ~base.columns.str.contains(\"Unnamed\")]\n",
    "\n",
    "    keep_cols = [\n",
    "        \"Squad\", \"Poss\", \"Gls\", \"Ast\", \"G+A\", \"Gls/90\", \"Ast/90\", \"G+A/90\",\n",
    "        \"xG\", \"npxG\", \"xAG\", \"npxG+xAG\", \"PrgC\", \"PrgP\"\n",
    "    ]\n",
    "    base = base[[c for c in keep_cols if c in base.columns]]\n",
    "    return base.reset_index(drop=True)\n",
    "\n",
    "def build_match_dataset(season):\n",
    "    fixtures = load_fixtures_for_season(season)\n",
    "    stats = load_stats_for_season(season)\n",
    "\n",
    "    merged = fixtures.merge(stats, left_on=\"HomeTeam\", right_on=\"Squad\", how=\"left\", suffixes=(\"\", \"_Home\"))\n",
    "    merged = merged.drop(columns=[\"Squad\"])\n",
    "    merged = merged.rename(columns={c: f\"Home_{c}\" for c in merged.columns if c not in fixtures.columns})\n",
    "\n",
    "    merged = merged.merge(stats, left_on=\"AwayTeam\", right_on=\"Squad\", how=\"left\", suffixes=(\"\", \"_Away\"))\n",
    "    merged = merged.drop(columns=[\"Squad\"])\n",
    "    merged = merged.rename(columns={c: f\"Away_{c}\" for c in merged.columns if c not in fixtures.columns})\n",
    "\n",
    "    return merged\n",
    "\n",
    "def add_rolling_form_features(df, window=5):\n",
    "    df = df.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    for team_col, prefix in [(\"HomeTeam\", \"HomeForm\"), (\"AwayTeam\", \"AwayForm\")]:\n",
    "        for team in df[team_col].unique():\n",
    "            team_matches = df[(df[\"HomeTeam\"] == team) | (df[\"AwayTeam\"] == team)].copy()\n",
    "            team_matches = team_matches.sort_values(\"Date\")\n",
    "\n",
    "            team_matches[\"Goals_For\"] = np.where(team_matches[\"HomeTeam\"] == team,\n",
    "                                                 team_matches[\"HomeGoals\"], team_matches[\"AwayGoals\"])\n",
    "            team_matches[\"Goals_Against\"] = np.where(team_matches[\"HomeTeam\"] == team,\n",
    "                                                     team_matches[\"AwayGoals\"], team_matches[\"HomeGoals\"])\n",
    "            team_matches[\"Points\"] = np.where(team_matches[\"Goals_For\"] > team_matches[\"Goals_Against\"], 3,\n",
    "                                              np.where(team_matches[\"Goals_For\"] == team_matches[\"Goals_Against\"], 1, 0))\n",
    "\n",
    "            team_matches[f\"{prefix}_Goals_For_rolling{window}\"] = team_matches[\"Goals_For\"].rolling(window).mean().shift(1)\n",
    "            team_matches[f\"{prefix}_Goals_Against_rolling{window}\"] = team_matches[\"Goals_Against\"].rolling(window).mean().shift(1)\n",
    "            team_matches[f\"{prefix}_Points_rolling{window}\"] = team_matches[\"Points\"].rolling(window).mean().shift(1)\n",
    "\n",
    "            df.loc[team_matches.index, f\"{prefix}_Goals_For_rolling{window}\"] = team_matches[f\"{prefix}_Goals_For_rolling{window}\"]\n",
    "            df.loc[team_matches.index, f\"{prefix}_Goals_Against_rolling{window}\"] = team_matches[f\"{prefix}_Goals_Against_rolling{window}\"]\n",
    "            df.loc[team_matches.index, f\"{prefix}_Points_rolling{window}\"] = team_matches[f\"{prefix}_Points_rolling{window}\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "# === Step 3: Build datasets ===\n",
    "\n",
    "train_data = pd.concat([build_match_dataset(s) for s in train_seasons], ignore_index=True)\n",
    "test_data = pd.concat([build_match_dataset(s) for s in test_seasons], ignore_index=True)\n",
    "\n",
    "train_data = add_rolling_form_features(train_data, window=5)\n",
    "test_data = add_rolling_form_features(test_data, window=5)\n",
    "\n",
    "train_data = train_data[train_data[\"is_played\"]]\n",
    "test_data = test_data[test_data[\"is_played\"]]\n",
    "\n",
    "feature_cols = [c for c in train_data.columns if (\"Home_\" in c or \"Away_\" in c) and c not in [\"HomeTeam\", \"AwayTeam\"]]\n",
    "\n",
    "X_train = train_data[feature_cols]\n",
    "y_train = train_data[\"Result\"]\n",
    "\n",
    "X_test = test_data[feature_cols]\n",
    "y_test = test_data[\"Result\"]\n",
    "\n",
    "# === Step 4: Train Model ===\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# === Step 5: Predict Future Matches (2025-26) ===\n",
    "\n",
    "predict_data = build_match_dataset(\"2025-26\")\n",
    "predict_data = add_rolling_form_features(predict_data, window=5)\n",
    "future_matches = predict_data[~predict_data[\"is_played\"]]\n",
    "\n",
    "X_future = future_matches[feature_cols]\n",
    "future_matches[\"Predicted_Result\"] = rf.predict(X_future)\n",
    "\n",
    "print(\"\\nUpcoming Predictions (2025-26):\")\n",
    "print(future_matches[[\"Date\", \"HomeTeam\", \"AwayTeam\", \"Predicted_Result\"]].head(25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5eaebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
